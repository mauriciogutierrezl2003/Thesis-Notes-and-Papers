
% Document class and packages
\documentclass[12pt,a4paper,openany]{report}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{braket}
\usepackage{float}
\usepackage{longtable}
\usepackage[style=apa,backend=biber]{biblatex}
\addbibresource{references.bib}



% Remove blank pages between chapters
\let\cleardoublepage\clearpage

% Title and author information
\title{Titel}
\author{Víctor Mauricio Gutiérrez Luque}
\date{25 11, 2025}

\begin{document}

% Title page
\maketitle

% Abstract
\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}


\tableofcontents

% Chapters
\chapter{Background and Introduction}
% ... contenido ...


\section{Quantum Computing Preliminaries}

\subsection{Behind Quantum Computing}
In the last century, there were measured results in classical physics giving absurdities. First, when people studied how hot objects glow, the old theory predicted they should emit infinite amounts or of UV light. Planck fixed this by suggesting that energy is not continuous, but discrete, counted in “packets” or quanta \parencite{planck_1900_blackbody}. Then the photoelectric effect showed that light can knock electrons out of metal only if its frequency is high enough; brightness or intensity of light alone did not help. Einstein explained this by saying light behaves like particles (photons), each carrying one energy packet \parencite{einstein_1905_photoelectric}. Then, atoms when heated were seen to emit only specific wavelengths or colors (spectral lines) and not a smooth rainbow. This made sense if electrons inside atoms can only have certain allowed energies. Bohr applied the quantum idea to atoms, proposing quantized energy levels for electrons in 1913, but without explaining why \parencite{bohr_1913_atom}. Later, de Broglie suggested that not only light, but also matter like electrons can act like waves; electron-diffraction experiments confirmed this \parencite{debroglie_1924_thesis}.

Heisenberg and Schr{\"o}dinger completed it by independently constructing new, self-consistent replacements for classical mechanics. Heisenberg started from the experimental fact that atomic spectra reveal only transitions between discrete energy levels. This led naturally to a matrix-based algebra in which the order of operations matters, capturing quantum behavior without relying on classical orbits. Schr{\"o}dinger, in contrast, searched for a wave equation governing microscopic systems of matter. This yielded correct bound-state energies and spectral predictions. They were soon shown to be mathematically equivalent descriptions of the same theory, and Born provided the probabilistic interpretation of the wavefunction \parencite{heisenberg_1925_matrix_mechanics,schrodinger_1926_wave_mechanics,born_1926_born_rule}. In short: classical physics failed for small-scale phenomena, and quantum mechanics was the new rulebook that fit the experiments.

In the classical computation model, information is encoded in bits and processed by deterministic or randomized operations, and the time and memory required by these operations determine what is computationally feasible. Quantum computing extends this model by introducing a new unit of information, the qubit, whose behavior follows the rules of quantum mechanics. Unlike a classical bit, which is always either 0 or 1, a qubit can occupy infinitely many states on a continuous state space; before measurement it can exist in a superposition of basis states; measurement irreversibly changes the qubit's state; and the outcome depends on the measurement basis, meaning the same qubit can be probed along many different axes \parencite{nielsen_chuang_qcqi}.

These features are valuable not because they allow unlimited extraction of information, but because they allow information to be encoded in complex amplitudes and phases, manipulated through continuous unitary transformations, and combined across qubits to produce interference and entanglement. 

Well-designed quantum algorithms exploit these effects so that, after a sequence of gates, the probability of measuring a desired result is amplified while unwanted outcomes are suppressed. These capabilities have no direct classical analogue. This mechanism is behind landmark quantum speedups such as Shor's algorithm for integer factoring and discrete logarithms, which runs in polynomial time on a quantum computer compared to the best known sub-exponential classical methods \parencite{shor_1994_focs,shor_1997_siam}, and Grover's algorithm for unstructured search, which reduces $O(N)$ classical query complexity to $O(\sqrt{N})$ using amplitude amplification \parencite{grover_1996_search}.

We will now first introduce the minimal linear-algebra language needed to describe quantum states and operations; then define qubits and single-qubit gates; extend to multi-qubit systems via tensor products and entanglement; and finally present the circuit model as the formal framework for quantum computation.

\subsection{Some Linear Algebra}

We briefly review the basic linear algebra concepts used throughout this thesis.\footnote{This overview is based on the exposition in \textcite[Chapter~2]{nielsen_chuang_qcqi}.}


A vector is a geometric object that as a magnitude and a direction and can live in a certain vector space, represented as columns whose values are in the domain. The basic operations are vector addition and scalar multiplication, and any expression of the form $\sum_i \alpha_i v_i$ is a linear combination of vectors $v_i$ with coefficients $\alpha_i$.

A map between vector spaces is linear if it respects these operations, $L(\alpha v + \beta w) = \alpha L(v) + \beta L(w)$. The standard Hermitian inner product is $\langle v,w\rangle = \sum_i \overline{v_i} w_i$, which induces the norm $\|v\| = \sqrt{\langle v,v\rangle}$. Two vectors are orthogonal if $\langle v,w\rangle = 0$, and a vector is normalized if $\|v\| = 1$. We often write vectors and inner products in bra--ket notation, where a column vector is denoted $\lvert v\rangle$, its conjugate transpose is $\langle v\rvert$, and the inner product is $\langle v \vert w\rangle$.

A basis $\{e_1,\dots,e_n\}$ of $\mathbb{C}^n$ is a set of vectors such that every vector has a unique coordinate representation $v = \sum_i \alpha_i e_i$; if, in addition, $\langle e_i,e_j\rangle = \delta_{ij}$, the basis is orthonormal. The standard (computational) basis of $\mathbb{C}^n$ consists of the unit vectors with a single $1$ in one position and $0$ elsewhere, and any vector can be written as a linear combination of these basis vectors.

Linear maps on the vector space are represented by matrices, and their action on a vector is given by matrix-vector multiplication; special directions that are only rescaled by a matrix are captured by eigenvectors $v$ with eigenvalues $\lambda$, satisfying $Av = \lambda v$. Of particular importance are unitary matrices $U$, defined by the condition $U^\dagger U = I$, where $U^\dagger$ is the conjugate transpose and $I$ is the identity. Unitary operators preserve inner products, and hence norms and angles, and are always reversible with inverse $U^{-1} = U^\dagger$.


\subsection{Postulates of Quantum Mechanics}


In this subsection we summarize the standard postulates of finite-dimensional quantum mechanics in the language of complex vector spaces introduced above. According more detailed discussion can be found in \textcite[Chapter~2]{nielsen_chuang_qcqi}.

\paragraph{Postulate 1 (State space).}
To every isolated physical system there corresponds a complex Hilbert space $\mathcal{H}$, called the state space of the system. The (pure) states of the system are represented by unit vectors $\lvert \psi \rangle \in \mathcal{H}$ with $\langle \psi \vert \psi \rangle = 1$. Two vectors that differ only by a nonzero complex scalar multiple represent the same physical state. In particular, $\lvert \psi \rangle$ and $e^{i\theta} \lvert \psi \rangle$ are physically indistinguishable for any real $\theta$.

\paragraph{Postulate 2 (Time evolution of closed systems).}
The time evolution of a closed system is described by a unitary operator on its state space. If the state at time $t_1$ is $\lvert \psi(t_1) \rangle$ and the state at time $t_2$ is $\lvert \psi(t_2) \rangle$, then there exists a unitary operator $U$ on $\mathcal{H}$ such that
\begin{equation}
  \lvert \psi(t_2) \rangle = U \lvert \psi(t_1) \rangle,
\end{equation}
where $U^\dagger U = I$. Unitary evolution preserves inner products and, in particular, the normalization of state vectors.

\paragraph{Postulate 3 (Measurement).}
Let $\{\lvert i \rangle\}$ be an orthonormal basis of the state space $\mathcal{H}$, and consider a measurement in this basis. Any state can be written as
\begin{equation}
  \lvert \psi \rangle = \sum_i \alpha_i \lvert i \rangle, \qquad \sum_i \lvert \alpha_i \rvert^2 = 1.
\end{equation}
The measurement has discrete outcomes labeled by $i$, and quantum mechanics assigns:
\begin{itemize}
  \item probability
  \begin{equation}
    p(i) = \lvert \alpha_i \rvert^2 = \lvert \langle i \vert \psi \rangle \rvert^2
  \end{equation}
  to obtaining outcome $i$;
  \item post-measurement state
  \begin{equation}
    \lvert \psi_i \rangle = \lvert i \rangle
  \end{equation}
  conditioned on observing outcome $i$.
\end{itemize}
Equivalently, this measurement can be described by the family of orthogonal projectors $P_i = \lvert i \rangle \langle i \rvert$, with $p(i) = \langle \psi \vert P_i \vert \psi \rangle$ and normalized post-measurement states $\lvert \psi_i \rangle = P_i \lvert \psi \rangle / \sqrt{p(i)}$. More general measurements can be modeled by a collection of measurement operators $\{M_m\}$ satisfying $\sum_m M_m^\dagger M_m = I$, but in this thesis we will primarily use projective measurements in the computational basis.

\paragraph{Postulate 4 (Composite systems).}
For a composite system consisting of subsystems $A$ and $B$ with state spaces $\mathcal{H}_A$ and $\mathcal{H}_B$, the state space of the combined system is the tensor product
\begin{equation}
  \mathcal{H}_{AB} = \mathcal{H}_A \otimes \mathcal{H}_B.
\end{equation}
If $\lvert \psi \rangle_A \in \mathcal{H}_A$ and $\lvert \phi \rangle_B \in \mathcal{H}_B$ are states of the individual subsystems, then the product state of the composite system is $\lvert \psi \rangle_A \otimes \lvert \phi \rangle_B$. More generally, a pure state of the composite system is any unit vector $\lvert \Psi \rangle_{AB} \in \mathcal{H}_A \otimes \mathcal{H}_B$, which can be expressed as
\begin{equation}
  \lvert \Psi \rangle_{AB} = \sum_{ij} \alpha_{ij} \lvert i \rangle_A \otimes \lvert j \rangle_B
\end{equation}
with respect to chosen orthonormal bases $\{\lvert i \rangle_A\}$ and $\{\lvert j \rangle_B\}$.
A pure state is called \emph{separable} if it can be written as $\lvert \Psi \rangle_{AB} = \lvert \psi \rangle_A \otimes \lvert \phi \rangle_B$ for some $\lvert \psi \rangle_A$ and $\lvert \phi \rangle_B$, otherwise \emph{entangled}.
Even when entangled qubits are spatially separated, a measurement on one qubit instantaneously fixes the conditional state of the others: once an outcome is obtained on one side, the outcome probabilities on the other side are updated accordingly.
For example, if
\[
|\psi\rangle = \begin{pmatrix} a \\ b \end{pmatrix}, \quad |\phi\rangle = \begin{pmatrix} c \\ d \end{pmatrix},
\]
then their tensor product is:
\[
|\psi\rangle \otimes |\phi\rangle = \begin{pmatrix} a c \\ a d \\ b c \\ b d \end{pmatrix}.
\]

\subsection{Quantum Computing}

Classical computers represent information using \textit{bits}, which can take values of either 0 or 1. Quantum computing generalizes this idea using \textit{quantum bits}, or \textit{qubits}.

A single qubit is a two-dimensional quantum system with state space $\mathcal{H} \cong \mathbb{C}^2$. Fixing the computational basis $\{\ket{0},\ket{1}\}$, any pure state of a qubit can be written as
\begin{equation}
  \ket{\psi} = \alpha \ket{0} + \beta \ket{1}, \qquad \alpha,\beta \in \mathbb{C}, \quad \lvert \alpha \rvert^2 + \lvert \beta \rvert^2 = 1.
\end{equation}
As global phases are irrelevant, because $\ket{\psi}$ and $e^{i\theta}\ket{\psi}$ describe the same physical state, we can use this to parametrize any qubit state by two real angles $\theta \in [0,\pi]$ and $\varphi \in [0,2\pi)$ as
\begin{equation}
  \ket{\psi(\theta,\varphi)} = \cos\!\left(\frac{\theta}{2}\right)\ket{0}
  + e^{i\varphi} \sin\!\left(\frac{\theta}{2}\right)\ket{1}.
\end{equation}
The pair $(\theta,\varphi)$ can be interpreted as spherical coordinates of a point on the unit sphere in $\mathbb{R}^3$. This represents the \emph{Bloch sphere}: every qubit state corresponds to a point on the surface of the sphere, with $\ket{0}$ and $\ket{1}$ at the north and south poles, respectively.


Unitary operators preserve inner products and norms, so they map pure states to pure states, corresponding to rotations. 

A \emph{single-qubit gate} is such a unitary operation applied to an individual qubit. Important examples include the Pauli operators
\begin{equation}
  X = \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix}, \quad
  Y = \begin{pmatrix} 0 & -i \\ i & 0 \end{pmatrix}, \quad
  Z = \begin{pmatrix} 1 & 0 \\ 0 & -1 \end{pmatrix},
\end{equation}
which generate $\pi$-rotations about the $x$-, $y$-, and $z$-axes of the Bloch sphere. The Pauli-$X$ gate exchanges $\ket{0}$ and $\ket{1}$ and is the quantum analogue of a classical NOT gate. The Pauli-$Z$ gate leaves $\ket{0}$ invariant and multiplies $\ket{1}$ by a phase $-1$, thereby changing relative phase without altering the measurement probabilities in the computational basis.

Another fundamental gate is the Hadamard operator
\begin{equation}
  H = \frac{1}{\sqrt{2}}\begin{pmatrix} 1 & 1 \\ 1 & -1 \end{pmatrix},
\end{equation}
which maps basis states to equal superpositions,
\begin{equation}
  H\ket{0} = \frac{\ket{0} + \ket{1}}{\sqrt{2}}, \qquad
  H\ket{1} = \frac{\ket{0} - \ket{1}}{\sqrt{2}}.
\end{equation}
The Hadamard gate is routinely used to create superposition states from computational basis states. More generally, one often considers continuous families of \emph{rotation gates}
\begin{equation}
  R_X(\theta) = e^{-i\theta X/2}, \quad
  R_Y(\theta) = e^{-i\theta Y/2}, \quad
  R_Z(\theta) = e^{-i\theta Z/2},
\end{equation}
which implement rotations of the Bloch vector by an angle $\theta$ around the corresponding axis, as well as phase gates such as
\begin{equation}
  S = \begin{pmatrix} 1 & 0 \\ 0 & i \end{pmatrix}, \qquad
  T = \begin{pmatrix} 1 & 0 \\ 0 & e^{i\pi/4} \end{pmatrix},
\end{equation}
which modify the relative phase between $\ket{0}$ and $\ket{1}$.

To describe multiple qubits within the formalism of Postulate~4, we use the tensor product to build composite systems. If each single qubit lives in a two-dimensional Hilbert space $\mathcal{H} \cong \mathbb{C}^2$ with basis $\{\ket{0},\ket{1}\}$, then the state space of an $n$-qubit register is the tensor product
\begin{equation}
  \mathcal{H}^{\otimes n} = \underbrace{\mathcal{H} \otimes \cdots \otimes \mathcal{H}}_{n \text{ times}} \cong \mathbb{C}^{2^n}.
\end{equation}
The computational basis of $\mathcal{H}^{\otimes n}$ consists of all $2^n$ tensor products of single-qubit basis states,
\begin{equation}
  \{\ket{x_1}\otimes \cdots \otimes \ket{x_n} : x_k \in \{0,1\}\},
\end{equation}
which are usually written more compactly as $\ket{x_1\cdots x_n}$ for $x_1\cdots x_n \in \{0,1\}^n$. Any pure $n$-qubit state can be expressed as a linear combination
\begin{equation}
  \ket{\Psi} = \sum_{x \in \{0,1\}^n} \alpha_x \ket{x}, \qquad \sum_{x} \lvert \alpha_x \rvert^2 = 1.
\end{equation}

A particularly simple class of multi-qubit states are \emph{product states}, which factorize as a tensor product of single-qubit states, for example
\begin{equation}
  \ket{\Psi} = \ket{\psi_1} \otimes \cdots \otimes \ket{\psi_n},
\end{equation}
with each $\ket{\psi_k} = \alpha_k \ket{0} + \beta_k \ket{1}$. However, Postulate~4 allows more general states that cannot be written in this factorized form, entangled states. Popular examples are the Bell states, such as
\begin{equation}
  \ket{\Phi^+} = \frac{1}{\sqrt{2}}\big(\ket{00} + \ket{11}\big).
\end{equation}

Measuring the first qubit of $\ket{\Phi^+}$ in the computational basis yields outcome $0$ or $1$ with equal probability, but conditioned on the outcome, the state of the second qubit is perfectly correlated: if the first outcome is $0$ the joint state collapses to $\ket{00}$, whereas if the first outcome is $1$ it collapses to $\ket{11}$. These correlations cannot be explained by any classical product state and are stronger than those obtainable from independent systems with shared classical randomness.

Entanglement plays a central role in quantum computation because it allows a quantum computer to represent and manipulate correlations across many subsystems in a way that has no direct classical analogue. In an $n$-qubit register, generic pure states live in a space of dimension $2^n$, and entangled states can encode joint amplitude patterns over all $2^n$ basis strings. 

It is important to distinguish entanglement from superposition. Superposition already appears at the single-qubit level: a state of the form $\ket{\psi} = \alpha\ket{0} + \beta\ket{1}$ is a superposition of basis states, but not entangled, because it concerns only one system. Every entangled state is also a superposition, but not every superposition is entangled. 

A quantum circuit consists of a sequence of quantum gates acting on a register of qubits. The structure of a quantum circuit reflects the algorithmic logic of the computation, with qubits initialized in known basis states, processed through a network of gates, and finally measured to extract classical information. Quantum algorithms exploit this structure by applying multi-qubit gates that create and transform entanglement, so that interference between many computational paths can be steered towards desired outcomes.

\subsubsection{Grover's Algorithm}

To illustrate the operation of a quantum circuit, consider Grover’s algorithm, which provides a quadratic speedup for the problem of searching an unstructured database. 
Grover's algorithm works as followed: given a function \( f: \{0,1\}^n \rightarrow \{0,1\} \) that evaluates to \( f(x) = 1 \) for a unique input \( x = x_0 \), and \( f(x) = 0 \) otherwise, the goal is to find \( x_0 \). Classically, this requires \( \mathcal{O}(2^n) \) evaluations in the worst case, whereas Grover's algorithm achieves this in \( \mathcal{O}(\sqrt{2^n}) \) steps.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\linewidth]{image.png}
    \caption{The quantum circuit for Grover’s algorithm}
    \label{fig:grover-circuit}
\end{figure}

\begin{enumerate}
    \item \textbf{Initialization}

    We begin with an \( n \)-qubit register initialized to the state \( \ket{0}^{\otimes n} \). Applying the Hadamard transform \( H^{\otimes n} \) yields the uniform superposition:

    \[
    \ket{\psi} = \frac{1}{\sqrt{N}} \sum_{x \in \{0,1\}^n} \ket{x}, \quad \text{where } N = 2^n.
    \]

    This state assigns equal probability amplitude to every possible input \( x \in \{0,1\}^n \).

    \item \textbf{Oracle Operator}

    The oracle \( V_f \) is a unitary operator that flips the sign of the amplitude of the solution \( x_0 \). Formally:

    \[
    V_f \ket{x} = 
    \begin{cases}
    - \ket{x} & \text{if } x = x_0, \\
    \phantom{-} \ket{x} & \text{otherwise}.
    \end{cases}
    \]

    This phase inversion does not reveal \( x_0 \), but encodes its identity into the quantum state.

   \item \textbf{Diffusion Operator or $\text{FLIP}_{*}$}

    The diffusion operator, often referred to as the inversion about the average, amplifies the probability amplitude of the solution. It is defined as:

    \[
    D = 2 \ket{\psi}\bra{\psi} - I,
    \]

    where \( \ket{\psi} \) is the initial uniform superposition and \( I \) is the identity matrix. When applied to a state \( \ket{\phi} \), the operator reflects \( \ket{\phi} \) about \( \ket{\psi} \).

    \item \textbf{Grover Iteration}

    One Grover iteration consists of applying the oracle followed by the diffusion operator:

    \[
    G = D \cdot V_f.
    \]

    The state after \( t \) iterations is:

    \[
    \ket{\psi^{(t)}} = G^t \ket{\psi}.
    \]

    It can be shown that each application of \( G \) rotates the state vector closer toward the solution state \( \ket{x_0} \) in a two-dimensional subspace spanned by \( \ket{x_0} \) and its orthogonal complement. The rotation angle \( \theta \) satisfies:

    \[
    \cos(\theta) = \sqrt{\frac{N - 1}{N}}, \quad \text{so } \theta \approx \frac{1}{\sqrt{N}} \text{ for large } N.
    \]

    To maximize the probability of measuring \( x_0 \), the number of iterations should be approximately:

    \[
    t = \left\lfloor \frac{\pi}{4} \sqrt{N} \right\rfloor.
    \]

    \item \textbf{Measurement and Success Probability}

    After applying \( t \) iterations, we measure the quantum state in the computational basis. With high probability (approaching 1 as \( N \to \infty \)), the outcome will be the desired value \( x_0 \). The overall complexity of the algorithm is therefore \( \mathcal{O}(\sqrt{N}) \), providing a quadratic speedup over classical brute-force search.
\end{enumerate}

\section{Classical Models in Machine Learning}


\section{Quantum Models in Machine Learning}


\section{Motivation: The Benchmarking Problem in QML}

\subsection{The benchmarking problem in quantum machine learning}
\label{subsec:benchmarking-qml}

Before large, fault-tolerant quantum computers are available, almost all empirical evidence about quantum machine learning (QML) comes from classical simulations of small quantum models or from experiments on noisy, few-qubit devices. In this regime, \emph{benchmarking}, systematically comparing quantum models against each other and against classical baselines on common tasks, is one of the few tools available to assess whether current ideas in QML actually deliver on their promised advantages.\footnote{See \textcite{bowles2024better} for a detailed discussion and extensive references to the benchmarking literature both in classical and quantum machine learning.} 

However, as \textcite{bowles2024better} argue, drawing robust conclusions from such benchmarks is surprisingly difficult: small design choices in datasets, model architectures, metrics, and hyperparameter tuning can drastically change which model ``wins''. This makes it hard to answer even seemingly simple questions such as whether a given quantum model is ``better than'' a classical one.

\begin{itemize}
  \item \textbf{Dataset choice has a huge impact.}  
  Classical ``no free lunch'' results already tell us that average performance of any learning algorithm depends strongly on the distribution of tasks considered. In practice, this means that simply changing which datasets are included in a benchmark, or how they are preprocessed, can completely reorder the ranking of methods. Empirically, even for standard classical models, fixing label errors in a dataset, changing the train--test split, or switching to a different evaluation metric can significantly shift which model appears best.\footnote{Concrete examples are discussed in \textcite{bowles2024better} and references therein.}
  In the QML setting, where many studies rely on only one or two small datasets, this sensitivity is even more problematic.
  
  \item \textbf{Benchmark design embeds many hidden choices.}  
  Beyond the data itself, numerous ``small'' design decisions shape the outcome:
  \begin{itemize}
    \item Architectural tweaks (new ansätze, exotic layers, etc.) are often advertised as innovations, but large-scale benchmarks suggest that they frequently have little consistent effect on performance.
    \item Hyperparameter optimisation (learning rates, layer counts, regularisation, kernel parameters, etc.) typically dominates performance: with enough tuning, a simple baseline can match or surpass more elaborate proposals.
    \item Different evaluation metrics (accuracy, F1-score, AUC, calibration measures, or cost-sensitive scores) reward different behaviour and may correlate poorly, so ``best'' can mean different things depending on what is measured.
    \item When computational cost is taken into account (e.g., training time, circuit evaluations, required hardware or simulator resources), rankings can reverse: a slightly more accurate model may be clearly inferior when efficiency is factored in.
  \end{itemize}
  For QML, these issues are amplified because each circuit evaluation is expensive and gradients can require thousands of shots or full-state simulations, so hyperparameter searches are hardware- and time-intensive.
  
  \item \textbf{Systematic positivity bias in the literature.}  
  A simple thought experiment illustrates a serious publication bias: suppose many research groups each try a large number of quantum models and datasets, but only submit papers when they find a configuration where the quantum model outperforms a classical baseline. Even if, on average, classical models tend to do better, the literature will still be dominated by positive results that claim ``quantum beats classical''. A small survey by \textcite{bowles2024better} of arXiv papers mentioning ``quantum machine learning'' and ``outperform'' indeed finds that the overwhelming majority report quantum or ``improved quantum'' models outperforming baselines, while only a tiny fraction report negative or neutral findings. This creates a misleading impression of steady progress, even if the underlying picture is much more mixed.
\end{itemize}

The conclusion is that broad questions of the form ``Are quantum models better than classical ones?'' cannot be answered by isolated experiments on a handful of small datasets. Instead, what can be meaningfully asked are \emph{narrow}, well-specified questions: for example, how the performance of a particular family of quantum models changes as a controlled difficulty parameter increases, or how sensitive a given ansatz is to noise, or how a quantum kernel compares to a specific classical kernel on a particular class of tasks. 

Carefully designed benchmarks must therefore emphasise controlled variation, reproducibility, and ablation-style comparisons over simple leaderboard rankings.

HERE SPECIFIC SETUP FROM PAPER AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA


\paragraph{What matters in a comparison?}

Given these challenges, \textcite{bowles2024better} argue that benchmarking should move beyond simplistic leaderboard questions and instead ask \emph{structural} questions about model design. Rather than only asking whether a quantum model outperforms a classical baseline, we should try to understand \emph{which parts} of the model are crucial and which can be replaced by classically simulable components without loss of performance. In other words, benchmarking should be used as an \emph{ablation tool} to probe the role of quantum resources.

Concretely, they propose constructing ``dequantised'' variants of QML models by systematically removing or restricting those ingredients that are specifically quantum, for example by
\begin{itemize}
  \item removing entangling gates and using only local, single-qubit rotations,
  \item restricting the gate set to Clifford operations (which admit efficient classical simulation),
  \item replacing unitary evolutions by stochastic maps, or
  \item simulating circuits with tensor-network methods such as Matrix Product States (MPS) with low bond dimension.
\end{itemize}
By comparing the original model to these non-quantum or classically tractable variants on the \emph{same} benchmarks, one can probe to what extent genuine quantum effects are responsible for any observed performance differences. When a dequantised variant matches the original model, this suggests that ``quantumness'' was not the decisive ingredient, at least on the tasks and scales considered.


Motivated by this perspective, the present work adopts a similar philosophy. Rather than taking the presence of quantum circuits as evidence of a quantum advantage, we use benchmarking as a tool to dissect our models. After introducing baseline variational quantum classifiers, we will \emph{remove} its specifically quantum features and study how performance changes. In particular, we investigate variants \emph{without entanglement} and with other classically simulable restrictions, following the dequantisation strategies suggested by \textcite{bowles2024better}. By comparing the original and dequantised models on controlled benchmarks, our goal is to understand not only \emph{how well} they perform, but also \emph{which aspects of their design truly require quantum resources}.


\chapter{Methodology}

\section{Dataset}

\section{Baseline VQC Model}

\section{Dequantisation Variants}

\subsection{No Entanglement}

\subsection{(Optional) Low-Bond-Dimension MPS}

\section{Training Setup}

\section{Evaluation Metrics}



\chapter{Experiments}

\section{Research Questions}

\section{Baseline Performance}

\section{No-Entanglement Performance}

\section{(Optional) MPS Performance}



\chapter{Results}

\section{Quantitative Results}

\section{Qualitative Results}



\chapter{Discussion}



\chapter{Conclusion and Outlook}




\printbibliography


\end{document}
