\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{apa/global//global/global}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {chapter}{Abstract}{1}{chapter*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{3}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\abx@aux@refcontext{apa/apasortcite//global/global}
\abx@aux@cite{0}{murphy2012}
\abx@aux@segm{0}{0}{murphy2012}
\abx@aux@refcontext{apa/apasortcite//global/global}
\abx@aux@cite{0}{murphy2012}
\abx@aux@segm{0}{0}{murphy2012}
\abx@aux@refcontext{apa/apasortcite//global/global}
\abx@aux@cite{0}{rosenblatt1958}
\abx@aux@segm{0}{0}{rosenblatt1958}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background and Preliminaries}{4}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Classical Machine Learning Models}{4}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Overview of Supervised Learning}{4}{subsection.2.1.1}\protected@file@percent }
\abx@aux@page{1}{4}
\abx@aux@page{2}{4}
\abx@aux@refcontext{apa/apasortcite//global/global}
\abx@aux@cite{0}{rosenblatt1958}
\abx@aux@segm{0}{0}{rosenblatt1958}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Linear Classifiers}{5}{subsection.2.1.2}\protected@file@percent }
\abx@aux@page{3}{5}
\abx@aux@page{4}{5}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Logistic Regression}{5}{subsection.2.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Support Vector Machine (SVM)}{5}{subsection.2.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.5}k-Nearest Neighbors (k-NN)}{6}{subsection.2.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.6}Kernel Methods }{6}{subsection.2.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.7}Naive Bayes}{7}{subsection.2.1.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.8}Gaussian Processes (GPs)}{7}{subsection.2.1.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.9}Neural Networks (MLPs)}{8}{subsection.2.1.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Quantum Computing and Quantum Machine Learning Basics}{8}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Quantum Computing}{8}{subsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Grover's Algorithm}{10}{section*.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces The quantum circuit for Grover’s algorithm}}{10}{figure.2.1}\protected@file@percent }
\newlabel{fig:grover-circuit}{{2.1}{10}{The quantum circuit for Grover’s algorithm}{figure.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Variational Quantum Classifiers (VQCs)}{12}{subsection.2.2.2}\protected@file@percent }
\abx@aux@refcontext{apa/apasortcite//global/global}
\abx@aux@cite{0}{schuld2018circuit}
\abx@aux@segm{0}{0}{schuld2018circuit}
\abx@aux@refcontext{apa/apasortcite//global/global}
\abx@aux@cite{0}{fellner2025quantum}
\abx@aux@segm{0}{0}{fellner2025quantum}
\abx@aux@refcontext{apa/apasortcite//global/global}
\abx@aux@cite{0}{fellner2025quantum}
\abx@aux@segm{0}{0}{fellner2025quantum}
\abx@aux@page{5}{13}
\abx@aux@refcontext{apa/apasortcite//global/global}
\abx@aux@cite{0}{mittal2023variational}
\abx@aux@segm{0}{0}{mittal2023variational}
\abx@aux@refcontext{apa/apasortcite//global/global}
\abx@aux@cite{0}{mittal2023variational}
\abx@aux@segm{0}{0}{mittal2023variational}
\abx@aux@page{6}{14}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces  Schematic of a Variational Quantum Classifier (VQC), adapted from \blx@tocontentsinit {0}\textcite {mittal2023variational}. The computation begins with $n$ qubits initialized in the state $\mathinner {|{0}\rangle }^{\otimes n}$. The classical input vector $\mathbf  {x} \in \mathbb  {R}^n$ is embedded into a quantum state via a data-encoding unitary $U_\phi (\mathbf  {x})$, known as the quantum feature map. This maps classical data into a high-dimensional Hilbert space. The state is then processed by a parameterized quantum circuit $U(\boldsymbol  {\theta })$ with trainable parameters. These variational blocks are often repeated multiple times (denoted by hyperparameter depth $d$) to increase expressivity. After the final unitary transformation, the qubits are measured. The measurement outcomes are used to compute a cost function, typically defined over expectation values of observables. A classical optimizer then updates the parameters $\boldsymbol  {\theta }$ to minimize the cost and this hybrid quantum–classical loop continues until it find this minimal cost convergence.}}{14}{figure.2.2}\protected@file@percent }
\newlabel{fig:vqc_architecture_detailed}{{2.2}{14}{Schematic of a Variational Quantum Classifier (VQC), adapted from \textcite {mittal2023variational}. The computation begins with $n$ qubits initialized in the state $\ket {0}^{\otimes n}$. The classical input vector $\mathbf {x} \in \mathbb {R}^n$ is embedded into a quantum state via a data-encoding unitary $U_\phi (\mathbf {x})$, known as the quantum feature map. This maps classical data into a high-dimensional Hilbert space. The state is then processed by a parameterized quantum circuit $U(\boldsymbol {\theta })$ with trainable parameters. These variational blocks are often repeated multiple times (denoted by hyperparameter depth $d$) to increase expressivity. After the final unitary transformation, the qubits are measured. The measurement outcomes are used to compute a cost function, typically defined over expectation values of observables. A classical optimizer then updates the parameters $\boldsymbol {\theta }$ to minimize the cost and this hybrid quantum–classical loop continues until it find this minimal cost convergence}{figure.2.2}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methodology}{15}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:methodology}{{3}{15}{Methodology}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Experimental Setup}{15}{section.3.1}\protected@file@percent }
\newlabel{sec:setup}{{3.1}{15}{Experimental Setup}{section.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Datasets}{15}{subsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Preprocessing}{16}{subsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Dataset Split}{16}{subsection.3.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}Classical Models}{16}{subsection.3.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.5}Quantum Model: Variational Quantum Classifier (VQC)}{16}{subsection.3.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.6}Training Procedure}{17}{subsection.3.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.7}Evaluation Metrics}{17}{subsection.3.1.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.8}Experimental Protocol and Tools and Environment}{18}{subsection.3.1.8}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Results and Discussion}{19}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:results}{{4}{19}{Results and Discussion}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Quantitative Comparison}{19}{section.4.1}\protected@file@percent }
\newlabel{sec:quantitative}{{4.1}{19}{Quantitative Comparison}{section.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Qualitative Analysis}{19}{section.4.2}\protected@file@percent }
\newlabel{sec:qualitative}{{4.2}{19}{Qualitative Analysis}{section.4.2}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusion and Future Work}{21}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\abx@aux@page{7}{22}
\abx@aux@page{8}{22}
\abx@aux@page{9}{22}
\abx@aux@read@bbl@mdfivesum{nohash}
\abx@aux@read@bblrerun
\abx@aux@defaultrefcontext{0}{fellner2025quantum}{apa/global//global/global}
\abx@aux@defaultrefcontext{0}{murphy2012}{apa/global//global/global}
\abx@aux@defaultrefcontext{0}{rosenblatt1958}{apa/global//global/global}
\gdef \@abspage@last{23}
